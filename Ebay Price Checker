import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
import os
import re
from selenium.webdriver.chrome.options import Options


item_name = input("What do you want to search?\n-> ")


options = Options()
options.add_argument('--headless')
options.add_argument('--disable-gpu')  # Last I checked this was necessary.
driver = webdriver.Chrome(os.getcwd() + "\\chromedriver.exe", options=options)
'''
driver = webdriver.Chrome(os.getcwd() + "\\chromedriver.exe")
'''

driver.get("http://www.ebay.com")
search = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, "gh-ac")))


search.send_keys(item_name)
search.send_keys(Keys.RETURN)

url = driver.current_url
res = requests.get(url)

soup = BeautifulSoup(res.text, "html5lib")

mail = soup.find_all("div", class_ = "s-item__info clearfix")
print(len(mail))
for m in mail:
    name = m.find("h3", class_ = re.compile("s-item__title.*")).text
    price = m.find("span", class_ = re.compile("s-item__price.*")).text
    ship = m.find("span", class_ = re.compile("s-item__shipping.*")).text.split()
    print("Name:", name, "\nPrice:", price , "Shipping:", ship[0])
    print()

driver.quit()
